{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolSeyoum/Drought_Forecasting_TimeSeries/blob/master/Trend_extra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<table style=\"width: 100%\">\n",
        "\t<tr>\n",
        "\t\t<td>\n",
        "\t\t<table style=\"width: 100%\">\n",
        "\t\t\t<tr>\n",
        "                <td ><center><font size=\"5\"><b>Module 49</b></font><center>\n",
        "                <center><font size=\"6\">Digital Innovations for Water Challenges</font><center></td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "                <td><center><font size=\"14\">Notebook 4.3</font><center></td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "                <td><center><font size=\"6\"><b>Trend from time series data</b></font><center></td>\n",
        "\t\t\t</tr>\n",
        "\t\t</table>\n",
        "\t\t</td>\n",
        "\t\t<td><center><img src='https://surfdrive.surf.nl/files/index.php/s/Xw3DUcZYO0lZIya/download?path=%2F&files=/ihe-delft-institute_unesco_fc-lr.jpg'></img></td>\n",
        "\t</tr>\n",
        "</table>\n",
        "</div>"
      ],
      "metadata": {
        "id": "hFZmP9FwWLgw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwxqzsEGaWz3"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8gDHulXaWz5"
      },
      "source": [
        "For this exercise, we focus on time series data of near-surface air temperature over time. We will downlaod near-surface air temperature data over the Arctic, where increasing temperatures are particularly apparent.\n",
        "\n",
        "We will download another subset of the dataset ERA5 monthly averaged data on single levels from 1979 to present.\n",
        "\n",
        "This notebook is adapted from  <a href=\"https://ecmwf-projects.github.io/copernicus-training-c3s/reanalysis-climatology.html\">Tutorial on Climatologies using Climate Data from C3S</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCbnoJCnaWz8"
      },
      "source": [
        "<style>\n",
        "td, th {\n",
        "   border: 1px solid white;\n",
        "   border-collapse: collapse;\n",
        "}\n",
        "</style>\n",
        "<table align=\"left\">\n",
        "  <tr>\n",
        "    <th>Run the tutorial on Colab: </th>\n",
        "    <th><a href=\"https://colab.research.google.com/github/ecmwf-projects/copernicus-training-c3s/blob/main/reanalysis-climatology.ipynb\">\n",
        "        <img src = \"https://colab.research.google.com/assets/colab-badge.svg\" alt = \"Colab\"></th>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4KfAtehaWz-"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQh8UJLKaW0A"
      },
      "source": [
        "## 1. Intall required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7jnOZQuaW0A"
      },
      "outputs": [],
      "source": [
        "!pip install cdsapi --quiet\n",
        "!pip install cartopy --quiet\n",
        "!pip install pymannkendall --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYQUj-rAaW0G"
      },
      "source": [
        "#### Import libraries\n",
        "\n",
        "We will be working with data in NetCDF format. To best handle this data we will use libraries for working with multidimensional arrays, in particular Xarray. We will also need libraries for plotting and viewing data, in this case we will use Matplotlib and Cartopy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByhUTnLraW0H"
      },
      "outputs": [],
      "source": [
        "# CDS API\n",
        "import cdsapi\n",
        "\n",
        "# Libraries for working with multidimensional arrays\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "\n",
        "import pymannkendall as mk # Libarary to do trend analysis\n",
        "\n",
        "# Libraries for plotting and visualising data\n",
        "import matplotlib.path as mpath\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "# Disable warnings for data download via API\n",
        "import urllib3\n",
        "urllib3.disable_warnings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OjI-9jEaW0H"
      },
      "source": [
        "#### Enter your CDS API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBL5o7meaW0J"
      },
      "outputs": [],
      "source": [
        "\n",
        "url = 'url: https://cds.climate.copernicus.eu/api'\n",
        "key = input(\"your uid and key: \")\n",
        "key = f\"key: {key}\"\n",
        "\n",
        "with open('/root/.cdsapirc', 'w') as f:\n",
        "    f.write('\\n'.join([url, key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify a data directory in which we will download our data and all output files that we will generate:"
      ],
      "metadata": {
        "id": "e8kCaoVMZuDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = './'"
      ],
      "metadata": {
        "id": "LpDt-aFEZ-XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download data"
      ],
      "metadata": {
        "id": "W8VKTD8AZ5wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi\n",
        "\n",
        "dataset = \"reanalysis-era5-single-levels-monthly-means\"\n",
        "request = {\n",
        "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
        "    \"variable\": [\"2m_temperature\"],\n",
        "    \"year\": [\n",
        "        \"1979\", \"1980\", \"1981\",\n",
        "        \"1982\", \"1983\", \"1984\",\n",
        "        \"1985\", \"1986\", \"1987\",\n",
        "        \"1988\", \"1989\", \"1990\",\n",
        "        \"1991\", \"1992\", \"1993\",\n",
        "        \"1994\", \"1995\", \"1996\",\n",
        "        \"1997\", \"1998\", \"1999\",\n",
        "        \"2000\", \"2001\", \"2002\",\n",
        "        \"2003\", \"2004\", \"2005\",\n",
        "        \"2006\", \"2007\", \"2008\",\n",
        "        \"2009\", \"2010\", \"2011\",\n",
        "        \"2012\", \"2013\", \"2014\",\n",
        "        \"2015\", \"2016\", \"2017\",\n",
        "        \"2018\", \"2019\", \"2020\",\n",
        "        \"2021\", \"2022\", \"2023\",\n",
        "        \"2024\"\n",
        "    ],\n",
        "    \"month\": [\n",
        "        \"01\", \"02\", \"03\",\n",
        "        \"04\", \"05\", \"06\",\n",
        "        \"07\", \"08\", \"09\",\n",
        "        \"10\", \"11\", \"12\"\n",
        "    ],\n",
        "    \"time\": [\"00:00\"],\n",
        "    'area': [90, -180, 66.55, 180,],\n",
        "    'data_format': 'netcdf_legacy',\n",
        "}\n",
        "\n",
        "client = cdsapi.Client()\n",
        "\n",
        "# Retrieve the data and download it to the specified target path\n",
        "client.retrieve(dataset, request).download(f'{DATADIR}era5_monthly_t2m_Arc.nc')"
      ],
      "metadata": {
        "id": "AqIX7mvkauSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd4H2EyaaW0P"
      },
      "outputs": [],
      "source": [
        "t2m = f'{DATADIR}era5_monthly_t2m_Arc.nc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaTZla5EaW0Q"
      },
      "outputs": [],
      "source": [
        "# Create Xarray Dataset\n",
        "ds = xr.open_dataset(t2m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvQgEsKPaW0Q"
      },
      "source": [
        "Now we can query our newly created Xarray dataset ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKi0jtMOaW0R"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C802HX2faW0S"
      },
      "source": [
        "We see that the dataset has one variable called **\"t2m\"**, which stands for \"2 metre temperature\", and three coordinates of **longitude**, **latitude** and **time**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKMNXSxgaW0V"
      },
      "outputs": [],
      "source": [
        "# Create Xarray Data Array\n",
        "da = ds['t2m']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrh2zzMGaW0V"
      },
      "source": [
        "Let's view this data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlFR3n41aW0W"
      },
      "outputs": [],
      "source": [
        "da"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNNCpk-oaW0W"
      },
      "source": [
        "#### Change temperature units from Kelvin to Celsius\n",
        "\n",
        "Notice that the ERA-5 temperature data are in units of `Kelvin`, the base unit for temperature in the International System of Units (SI). If you want to convert the values from `Kelvin` to `degrees Celsius`, you have to subtract 273.15."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKWciVrPaW0X"
      },
      "outputs": [],
      "source": [
        "da_degc = da - 273.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtKnGglaaW0Y"
      },
      "source": [
        "If you inspect the characteristics of the data above, you see that when you convert the data values, the data array's Attributes are dropped. However, we want to keep the information provided by the Attributes and for this reason, we re-assign the attributes from the previous, unconverted object with the function assign_attrs(). Since the unit has changed, we assign a new unit measure to the units attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylJkuZ2caW0Y"
      },
      "outputs": [],
      "source": [
        "da_degc = da_degc.assign_attrs(da.attrs)\n",
        "da_degc.attrs['units'] = '° C'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "da_degc\n"
      ],
      "metadata": {
        "id": "fVHzh8ZYQa3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VELiN3poaW0a"
      },
      "source": [
        "#### Plot data\n",
        "\n",
        "Now, let us visualize one time step to get a better idea of the data. xarray offers built-in matplotlib functions that allow you to plot a `DataArray`. With the function `plot()`, you can easily plot e.g. the first time step of the loaded array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_JKOYi7aW0b"
      },
      "outputs": [],
      "source": [
        "da_degc[0,:,:].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr-XSvCcaW0d"
      },
      "source": [
        "An alternative to the built-in xarray plotting functions is to make use of a combination of the plotting libraries [matplotlib](https://matplotlib.org/) and [Cartopy](https://scitools.org.uk/cartopy/docs/latest/). One of Cartopy's key features is its ability to transform array data into different geographic projections. In combination with matplotlib, it is a very powerful way to create high-quality visualisations and animations. In later plots, we will make use of these libraries to produce more customised visualisations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LvDP-rraW1k"
      },
      "source": [
        "Let's view the first time step of this data. Notice that we change the projection from `ccrs.PlateCarree()` to `ccrs.Orthographic(central_latitude=90)` to better view the Arctic region. Note that we need to insert a `transform` keyword in the `pcolormesh` function to transform the data values into the orthographic projection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhPUjsySaW1l"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize = (8, 8), subplot_kw={'projection': ccrs.Orthographic(central_latitude=90)})\n",
        "\n",
        "im = ax.pcolormesh(da_degc.longitude, da_degc.latitude, da_degc[0,:,:], transform = ccrs.PlateCarree(), cmap='coolwarm')\n",
        "ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
        "ax.set_title('Near-surface air temperature, Jan 1979', fontsize=16)\n",
        "ax.coastlines(color='black')\n",
        "\n",
        "cbar = fig.colorbar(im, fraction=0.04, pad=0.07)\n",
        "cbar.set_label('° C')\n",
        "\n",
        "fig.savefig(f'{DATADIR}ERA5_Arctic_t2m_Jan1979.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjdJKE4RaW1n"
      },
      "source": [
        "#### Aggregate over geographical lat/lon dimensions\n",
        "\n",
        "We would like to analyse the time series of near-surface air temperature aggregated over the Arctic. To do this we need to average over the latitude and longitude dimensions.\n",
        "\n",
        "A very important consideration however is that the gridded data cells do not all correspond to the same areas. The size covered by each data point varies as a function of latitude. We need to take this into account when averaging. One way to do this is to use the cosine of the latitude as a proxy for the varying sizes.\n",
        "\n",
        "First, we calculate the weights by using the cosine of the latitude, then we apply these weights to the data array with the xarray function `weighted()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBCbkaYyaW1q"
      },
      "outputs": [],
      "source": [
        "weights = np.cos(np.deg2rad(da_degc.latitude))\n",
        "weights.name = \"weights\"\n",
        "da_degc_weighted = da_degc.weighted(weights)\n",
        "da_degc_mean = da_degc_weighted.mean([\"longitude\", \"latitude\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSm8L-BBaW1r"
      },
      "source": [
        "Let us create a simple plot of this data to see how it looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktLFk5XAaW1r"
      },
      "outputs": [],
      "source": [
        "da_degc_mean.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX9YmwneaW1t"
      },
      "source": [
        "Notice that the `plot()` function now creates a graph of temperature as a function of time.\n",
        "\n",
        "The trend in rising temperatures in the past decades is particularly noticable in the Arctic, and it is much easier to see this if we view the time series of yearly averages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3JSBzs7aW1u"
      },
      "outputs": [],
      "source": [
        "da_degc_yearly = da_degc_mean.groupby('time.year').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z48zgsmJaW1u"
      },
      "outputs": [],
      "source": [
        "da_degc_yearly.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBN2lkH-aW1w"
      },
      "source": [
        "Here we can see a clear warming trend. However we need to do trend analysis to confirm if there is a trend or not. Here we can use Mann-Kendall test to do the trend analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4WFaTqaW1x"
      },
      "source": [
        "A typical way to view such a time series is to convert the absolute temperature values into anomalies with respect to a climate normal and view the time series as a bar chart. This can clearly highlight which years were on average warmer or cooler than the climate normal."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let us do the trend analysis on the yearly timeseries."
      ],
      "metadata": {
        "id": "nkWdZM6ikQ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_MK_test_results(result):\n",
        "  print(f\"trend      = '{result.trend}'\")\n",
        "  print(f\"h          = {result.h}\")\n",
        "  print(f\"p          = {result.p:.3f}\")\n",
        "  print(f\"z          = {result.z:.2f}\")\n",
        "  print(f\"tau        = {result.Tau:.2f}\")\n",
        "  print(f\"slope      = {result.slope:.2f}\")\n",
        "  print(f\"intercept  = {result.intercept:.2f}\")"
      ],
      "metadata": {
        "id": "I9ZkCvI1pxcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_yearly = mk.original_test(da_degc_yearly)\n",
        "\n",
        "# Print the results\n",
        "print(result_yearly)\n",
        "print_MK_test_results(result_yearly)\n",
        "\n"
      ],
      "metadata": {
        "id": "YFzggzbHkQUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us do monthly data"
      ],
      "metadata": {
        "id": "czzX9I5Sk-4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_monthly = mk.original_test(da_degc_mean)\n",
        "\n",
        "# Print the results\n",
        "print_MK_test_results(result_monthly)"
      ],
      "metadata": {
        "id": "RiB3VJJ1lGS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data has seasonality, the original MK test is not suitable. In this case we can try to use the MK test for seasonl data.\n"
      ],
      "metadata": {
        "id": "eO9NhXtblZOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seasonal Kendall Test (monthly seasonality)\n",
        "result_seasonal = mk.seasonal_test(da_degc_mean, period=12)\n",
        "\n",
        "print_MK_test_results(result_seasonal)"
      ],
      "metadata": {
        "id": "iodXBpq6lxo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Interpret the MK test results:\n",
        "\n",
        "1. trend - Qualitative direction of change\n",
        "\n",
        "| Value        | Meaning                  |\n",
        "| ------------ | ------------------------ |\n",
        "| `increasing` | Monotonic upward trend   |\n",
        "| `decreasing` | Monotonic downward trend |\n",
        "| `no trend`   | No significant trend     |\n",
        "\n",
        "\n",
        "2. h (Hypothesis Test Result)\n",
        "\n",
        "the null hypothesis (H0) - no monotonic trend is present in the data,\n",
        "the alternate hypothesis (H1) - monotonic trend is present in the data\n",
        "\n",
        "| Value        | Meaning                  |\n",
        "| ------------ | ------------------------ |\n",
        "| `True` | Reject null hypothesis. There is a statistically significant trend.   |\n",
        "| `False` | annot reject null. Trend not statistically significant |\n",
        "\n",
        "\n",
        "3. p (p-value) - Strength of evidence against “no trend”\n",
        "\n",
        "| p-value  | Interpretation            |\n",
        "| -------- | ------------------------- |\n",
        "| p < 0.01 | Very strong evidence      |\n",
        "| p < 0.05 | Statistically significant |\n",
        "| p ≥ 0.05 | Not significant           |\n",
        "\n",
        "\n",
        "4. z (Standard Normal Statistic) - Distance from “no trend” in standard deviations\n",
        "\n",
        "| Z     | Meaning          |\n",
        "| ----- | ---------------- |\n",
        "| Z > 0 | Increasing trend |\n",
        "| Z < 0 | Decreasing trend |\n",
        "\n",
        "\n",
        "5. tau (Kendall’s Tau) - Strength of monotonic relationship\n",
        "  Range of tau: −1 ≤ tau ≤ +1\n",
        "\n",
        "\n",
        "6. slope (Sen’s Slope) - Magnitude of trend in units per time step\n",
        "\n",
        "\n",
        "7. intercept - Value at time zero.\n",
        "\n"
      ],
      "metadata": {
        "id": "_jUYCWU4q54E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Interpret the MK test results for the above three cases."
      ],
      "metadata": {
        "id": "trsVn1cxt9z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "================================================================================\n",
        "## Extra: How to clip and extract a timeseries for a point location"
      ],
      "metadata": {
        "id": "pFW0m9xSqxhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downlaod your data"
      ],
      "metadata": {
        "id": "pEWSOZfemEPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bounding box of Ethiopia as extracted from QGIS\n",
        " [32.9918000000000688,3.4066700000000765 : 47.9882400000000757,14.8836100000000897]\n",
        "\n",
        "Remember when you define the area bound, the order is North, West, South and East"
      ],
      "metadata": {
        "id": "1s6dAWDorK4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi\n",
        "\n",
        "dataset = \"reanalysis-era5-single-levels-monthly-means\"\n",
        "request = {\n",
        "    \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
        "    \"variable\": [\"2m_temperature\"],\n",
        "    \"year\": [\n",
        "        \"1979\", \"1980\", \"1981\",\n",
        "        \"1982\", \"1983\", \"1984\",\n",
        "        \"1985\", \"1986\", \"1987\",\n",
        "        \"1988\", \"1989\", \"1990\",\n",
        "        \"1991\", \"1992\", \"1993\",\n",
        "        \"1994\", \"1995\", \"1996\",\n",
        "        \"1997\", \"1998\", \"1999\",\n",
        "        \"2000\", \"2001\", \"2002\",\n",
        "        \"2003\", \"2004\", \"2005\",\n",
        "        \"2006\", \"2007\", \"2008\",\n",
        "        \"2009\", \"2010\", \"2011\",\n",
        "        \"2012\", \"2013\", \"2014\",\n",
        "        \"2015\", \"2016\", \"2017\",\n",
        "        \"2018\", \"2019\", \"2020\",\n",
        "        \"2021\", \"2022\", \"2023\",\n",
        "        \"2024\"\n",
        "    ],\n",
        "    \"month\": [\n",
        "        \"01\", \"02\", \"03\",\n",
        "        \"04\", \"05\", \"06\",\n",
        "        \"07\", \"08\", \"09\",\n",
        "        \"10\", \"11\", \"12\"\n",
        "    ],\n",
        "    \"time\": [\"00:00\"],\n",
        "    'area': [14.9, 32.98, 3.4, 47.99,],\n",
        "    'data_format': 'netcdf_legacy',\n",
        "}\n",
        "\n",
        "client = cdsapi.Client()\n",
        "\n",
        "# Retrieve the data and download it to the specified target path\n",
        "client.retrieve(dataset, request).download(f'{DATADIR}era5_monthly_t2m_Ethio.nc')"
      ],
      "metadata": {
        "id": "IjxltFS1ekul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2m_et = f'{DATADIR}era5_monthly_t2m_Ethio.nc'\n",
        "ds_eth = xr.open_dataset(t2m_et)\n",
        "ds_eth"
      ],
      "metadata": {
        "id": "sFhWIehkgPoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_eth.t2m[0].plot()"
      ],
      "metadata": {
        "id": "evMEkQ-HiHrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clip the data to your region of interest."
      ],
      "metadata": {
        "id": "F6T7M1OZmZYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas --quiet\n",
        "!pip install rioxarray --quiet"
      ],
      "metadata": {
        "id": "B60EtGj6iOqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload shapefile of your area of interest\n"
      ],
      "metadata": {
        "id": "To5jwcUcjPSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import rioxarray as rio\n",
        "region_shp = r'/content/Ethiopia_shp.geojson'\n",
        "shp = gpd.read_file(region_shp).to_crs('EPSG:4326')\n",
        "shp.plot()"
      ],
      "metadata": {
        "id": "y86u4AWfid3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clip the data using your area of interest\n",
        "da_eth = ds_eth.t2m\n",
        "da_eth = da_eth.rio.write_crs(\"EPSG:4326\", inplace=False)\n",
        "da_et_clipped = da_eth.rio.clip(shp.geometry.values, shp.crs, all_touched=True)\n",
        "da_et_clipped[0].plot()"
      ],
      "metadata": {
        "id": "996P5R0rjpgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract the data for your point location"
      ],
      "metadata": {
        "id": "JdTYngqLmhfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lat lon of Adis Ababa\n",
        "lat = 9.0192\n",
        "lon = 38.7525\n",
        "\n",
        "# Extract time series (nearest grid cell)\n",
        "ts = da_et_clipped.sel(\n",
        "    latitude=lat,\n",
        "    longitude=lon,\n",
        "    method=\"nearest\"\n",
        ")\n",
        "\n",
        "print(ts)"
      ],
      "metadata": {
        "id": "FZWBnF1BmmWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts.plot()"
      ],
      "metadata": {
        "id": "_wJHT2LknyJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute min and max over space for each time step\n",
        "min_ts = da_et_clipped.min(dim=(\"latitude\", \"longitude\"))\n",
        "max_ts = da_et_clipped.max(dim=(\"latitude\", \"longitude\"))\n",
        "\n",
        "# Convert to pandas (optional)\n",
        "min_ts_df = min_ts.to_pandas()\n",
        "max_ts_df = max_ts.to_pandas()\n",
        "\n",
        "min_ts_df.plot()"
      ],
      "metadata": {
        "id": "db7kuCJZoTF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_ts_df.plot()"
      ],
      "metadata": {
        "id": "8LVHbWjaoqs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "\n",
        "# Mean time series\n",
        "plt.plot(ts[\"time\"], ts, label=\"Mean\")\n",
        "\n",
        "# Min–max envelope\n",
        "plt.fill_between(\n",
        "    ts[\"time\"],\n",
        "    min_ts,\n",
        "    max_ts,\n",
        "    alpha=0.3,\n",
        "    label=\"Min–Max range\"\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Variable units\")\n",
        "plt.title(\"Mean Time Series with Min–Max Bounds\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZplIhzi3pTOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}